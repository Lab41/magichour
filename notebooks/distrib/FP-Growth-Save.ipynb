{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditd to transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs = sc.textFile(\"hdfs:///user/ytesfaye/lab41_logs_small.log.gz\").repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "type_lookup_table = {u'ADD_GROUP': 4,\n",
    " u'ADD_USER': 12,\n",
    " u'ANOM_ABEND': 0,\n",
    " u'CONFIG_CHANGE': 24,\n",
    " u'CRED_ACQ': 20,\n",
    " u'CRED_DISP': 13,\n",
    " u'CRED_REFR': 17,\n",
    " u'CRYPTO_KEY_USER': 6,\n",
    " u'CRYPTO_SESSION': 14,\n",
    " u'DAEMON_END': 8,\n",
    " u'DAEMON_START': 7,\n",
    " u'LOGIN': 19,\n",
    " u'NETFILTER_CFG': 22,\n",
    " u'SYSCALL': 5,\n",
    " u'SYSTEM_RUNLEVEL': 1,\n",
    " u'SYSTEM_SHUTDOWN': 18,\n",
    " u'USER_ACCT': 9,\n",
    " u'USER_AUTH': 10,\n",
    " u'USER_CHAUTHTOK': 21,\n",
    " u'USER_CMD': 3,\n",
    " u'USER_END': 23,\n",
    " u'USER_ERR': 11,\n",
    " u'USER_LOGIN': 2,\n",
    " u'USER_LOGOUT': 15,\n",
    " u'USER_START': 16}\n",
    "def get_data(line, window_size=10, start_time=1422496861):\n",
    "    timestamp = float(re.search('audit\\(([0-9]+.[0-9]+)', line).group(1))\n",
    "    type_code = type_lookup_table[re.search('type=([A-Z_]+) ', line).group(1)]\n",
    "    window = int((timestamp -start_time)/window_size)\n",
    "    return (window, type_code)\n",
    "from collections import defaultdict\n",
    "def get_longest_sets_possible(input_sets):\n",
    "    def is_subset(main_set, item):\n",
    "        is_subset = False\n",
    "        for main_item in main_set:\n",
    "            if item.issubset(main_item):\n",
    "                is_subset = True\n",
    "        return is_subset\n",
    "    input_dict = defaultdict(set)\n",
    "    for i in input_sets:\n",
    "        input_dict[len(i)].add(i)\n",
    "    \n",
    "    output_sets = set()\n",
    "    lengths = sorted(input_dict.keys(), reverse=True) # Largest first\n",
    "    for i in input_dict[lengths[0]]: # since they are all the longest length we know that they are good\n",
    "        output_sets.add(i) \n",
    "    \n",
    "    for length in lengths[1:]:\n",
    "        for item in input_dict[length]:\n",
    "            if not is_subset(output_sets, item):\n",
    "                output_sets.add(item)\n",
    "    return output_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions = logs.map(get_data) \\\n",
    "                   .groupByKey() \\\n",
    "                   .map(lambda (key, iterator): list(set(iterator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tBird Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tbird_logs = sc.textFile(\"hdfs:///user/ytesfaye/tbird.log.out.logCluster.processed.gz\").repartition(10)\n",
    "def get_tbird_data(line, window_size=10, start_time=1131523501):\n",
    "    ls = line.split(',')\n",
    "    timestamp = float(ls[0])\n",
    "    type_code = int(ls[1])\n",
    "    window = int((timestamp -start_time)/window_size)\n",
    "    return (window, type_code)\n",
    "transactions = tbird_logs.map(get_tbird_data) \\\n",
    "                   .filter(lambda (x, y): y != -1) \\\n",
    "                   .groupByKey() \\\n",
    "                   .map(lambda (key, iterator): list(set(iterator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ML Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.fpm import FPGrowth\n",
    "model = FPGrowth.train(transactions, minSupport=0.2, numPartitions=10)\n",
    "result = model.freqItemsets().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "items = [frozenset(fi.items) for fi in result]\n",
    "pruned_items = list(get_longest_sets_possible(items))\n",
    "for item in pruned_items:\n",
    "    print '|'.join([',' + str(i) + ',' for i in sorted(item, key=int)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manaul Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "combo_counts = transactions.flatMap(lambda l: list([((i1,i2),1) for i1, i2 in itertools.combinations(l, 2)])).countByKey()\n",
    "individual_counts = transactions.flatMap(lambda l: l).countByValue()\n",
    "num_transactions = transactions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_support = .2\n",
    "min_confidence = .95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute counts for each pair\n",
    "combo_counts = transactions.flatMap(lambda l: list([((i1,i2),1) for i1, i2 in itertools.combinations(l, 2)])).countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find Combinations exceeding min support\n",
    "pairs = []\n",
    "combo_counts_dict = dict(combo_counts) # So we don't add items we access\n",
    "for i1, i2 in combo_counts_dict:\n",
    "    support = get_pair_support(i1, i2)\n",
    "    confidence = get_confidence(i1,i2)\n",
    "    if support > min_support and confidence > min_confidence:\n",
    "        pairs.append((i1,i2))\n",
    "        #print support, get_confidence(i1, i2), d, i1, i2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_support(item):\n",
    "    return individual_counts[item]/float(num_transactions)\n",
    "def get_pair_support(item1, item2):\n",
    "    return (combo_counts[(item1, item2)] + combo_counts[(item2, item1)]) /float(num_transactions)\n",
    "def get_confidence(item1, item2):\n",
    "    return float(get_pair_support(item1, item2))/get_support(item1)\n",
    "def get_lift(item1, item2):\n",
    "    return float(get_pair_support(item1, item2))/(get_support(item1)*get_support(item2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
