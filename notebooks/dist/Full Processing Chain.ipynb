{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logs = 'hdfs://namenode/datasets/magichour/tbird.log.gz'\n",
    "logs = 'hdfs://namenode/magichour/tbird/'\n",
    "trans = 'hdfs://namenode/magichour/simpleTrans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.addPyFile('magichour/preProcess/preProcess_SPARK.py')\n",
    "sc.addPyFile('magichour/LogCluster/LogCluster.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preProcess_SPARK import rdd_preProcess\n",
    "from LogCluster import log_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_processed_lines = rdd_preProcess(sc, trans, logs, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "templates = log_cluster(sc, pre_processed_lines, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[' '.join(template) for template in templates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs = 'hdfs://namenode/datasets/magichour/tbird.log.gz'\n",
    "logs = 'hdfs://namenode/user/dgrossman/tbird.log.10000.gz'\n",
    "trans = 'hdfs://namenode/magichour/simpleTrans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = sc.textFile(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l.saveAsTextFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs = 'hdfs://namenode/magichour/tbird/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.addPyFile('magichour/magichour/lib/LogCluster/LogCluster.py')\n",
    "sc.addPyFile('magichour/magichour/api/local/preprocess/preProcess_SPARK.py')\n",
    "sc.addPyFile('magichour/magichour/api/local/preprocess/readLog_RDD.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preProcess_SPARK import rdd_preProcess\n",
    "from readLog_RDD import rdd_ReadLog\n",
    "from LogCluster import log_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rddLogs = rdd_ReadLog(sc,logs).repartition(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessed_logs = rdd_preProcess(sc,trans,rddLogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frequent_words, templates = log_cluster(sc, preprocessed_logs, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[' '.join(template) for template in templates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rddLogs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = rddLogs.take(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed = preprocessed_logs.take(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[p.processed for p in processed[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessed_logs.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from LogCluster import *\n",
    "\"\"\"\n",
    "Run log cluster\n",
    "Args:\n",
    "     log_lines(rdd of LogLine): Input log messages as LogLine objects\n",
    "     support(int): Threshold # of occurrences before a pattern can be included\n",
    "Returns:\n",
    "    list[list[str]]: Returns a list of pattern strings (where the pattern is a list of strings) for the log lines\n",
    "\"\"\"\n",
    "frequent_word_dict = preprocessed_logs.flatMap(parse_words)\\\n",
    "                             .reduceByKey(lambda x,y: x+y)\\\n",
    "                             .filter(lambda (key,count): count > 1000)\\\n",
    "                             .collectAsMap()\n",
    "\n",
    "frequent_words = sc.broadcast(set(frequent_word_dict.keys()))\n",
    "\n",
    "#return log_lines.map(lambda x: extract_patterns(x, frequent_words))\\\n",
    "#              .groupByKey()\\\n",
    "#              .filter(lambda (freq_word_pattern, pattern): len(pattern) > support)\\\n",
    "#              .map(collapse_patterns)\\\n",
    "#              .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(frequent_word_dict, open('freq_word_dict.json', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dump(templates, open('templates.json', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessed_logs.filter(lambda x: 'SWEEP' in x.processed and 'ib_sm' in x.processed).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = preprocessed_logs.filter(lambda x: 'SWEEP' in x.processed)\\\n",
    "        .map(lambda x: extract_patterns(x, frequent_words))\\\n",
    "             .groupByKey()\\\n",
    "             .filter(lambda (freq_word_pattern, pattern): len(pattern) > 1000)\\\n",
    "             .map(collapse_patterns)\\\n",
    "             .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c[1].processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "templates2 = preprocessed_logs.map(lambda x: extract_patterns(x, frequent_words))\\\n",
    "                .reduceByKey(lambda l1,l2: agg(l1, l2))\\\n",
    "                .filter(lambda (key, val): isinstance(val[0], int) and val[0] > 1000)\\\n",
    "                .collect()\n",
    "    #\\\n",
    "               #.filter(lambda (freq_word_pattern, pattern): len(pattern) > 1000)\\\n",
    "#               .collect()\n",
    "#              .map(collapse_patterns)\\\n",
    "#              .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(templates2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "templates2[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_next_pair(input_list):\n",
    "    '''\n",
    "    Iterator over input lists that returns skip_count, word pairs\n",
    "    '''\n",
    "    count = None\n",
    "    i = 0\n",
    "    while i < len(input_list):\n",
    "        if isinstance(input_list[i], int):\n",
    "            count = set([input_list[i]])\n",
    "        elif isinstance(input_list[i], set):\n",
    "            count = input_list[i]\n",
    "        else: #str\n",
    "            yield (count, input_list[i])\n",
    "            count = None\n",
    "        i += 1\n",
    "\n",
    "    yield (count, None)\n",
    "\n",
    "\n",
    "def combine_sets(s1, s2):\n",
    "    if s1 is None and s2 is None:\n",
    "        return None\n",
    "\n",
    "    if s1 is None:\n",
    "        return s2\n",
    "    elif s2 is None:\n",
    "        return s1\n",
    "    else:\n",
    "        return s1.union(s2)\n",
    "\n",
    "\n",
    "def agg(l1, l2):\n",
    "    if isinstance(l1, list):\n",
    "        l1_count = 1\n",
    "    elif isinstance(l1, tuple):\n",
    "        l1_count = l1[0]\n",
    "        l1 = l1[1]\n",
    "    else:\n",
    "        raise TypeError('Expcted list or tuple, found: %s'%type(l1))\n",
    "    \n",
    "    if isinstance(l2, list):\n",
    "        l2_count = 1\n",
    "    else:\n",
    "        l2_count = l2[0]\n",
    "        l2 = l2[1]\n",
    "    \n",
    "    if not isinstance(l1_count, int) or not isinstance(l2_count, int):\n",
    "        raise ValueError('Incorrect format: %s|%s'%(l1_count, l2_count))\n",
    "    \n",
    "    output = []\n",
    "    for (i1, i2) in zip(get_next_pair(l1), get_next_pair(l2)):\n",
    "\n",
    "        combined_count = combine_sets(i1[0], i2[0])\n",
    "        if combined_count is not None:\n",
    "            output.append(combined_count)\n",
    "\n",
    "        if i1[1] != i2[1]:\n",
    "            raise ValueError('These should match, instead: %s %s'%(l1, l2))#(i1[1], i2[1]))\n",
    "        if i1 is not None:\n",
    "            output.append(i1[1])\n",
    "\n",
    "    return (l1_count + l2_count, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isinstance(tuple([1,2]), list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cdef int a = 0\n",
    "for i in range(10):\n",
    "    a += i\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hadoop fs -ls /magichour/matchedTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
