{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import re\n",
    "\n",
    "TransformLine = namedtuple('TransformLine',\n",
    "                           ['id', 'type', 'NAME', 'transform', 'compiled'])\n",
    "\n",
    "LogLine = namedtuple('LogLine', ['ts', 'msg',\n",
    "                                 'processed', 'dictionary', 'supportId'])\n",
    "\n",
    "\n",
    "def rdd_TransformLine(line):\n",
    "    '''\n",
    "    process transformations into RDD format\n",
    "\n",
    "    Args:\n",
    "        line(string): line from the transform defintion file.\n",
    "                      lines beginning with # are considered comments\n",
    "                      and will need to be removed\n",
    "    Returns:\n",
    "        retval(TransformLine): namedTuple representation of the tasking\n",
    "    '''\n",
    "\n",
    "    if line.lstrip()[0] != '#':\n",
    "        # id,type,name,transform\n",
    "        l = line.lstrip().rstrip().split(',', 3)\n",
    "        return TransformLine(int(l[0]), l[1], l[2], l[3], re.compile(l[3]))\n",
    "    else:\n",
    "        return TransformLine('COMMENT',\n",
    "                             'COMMENT',\n",
    "                             'COMMENT',\n",
    "                             'COMMENT',\n",
    "                             'COMMENT')\n",
    "\n",
    "\n",
    "def rdd_LogLine(line):\n",
    "    '''\n",
    "    process a log line into a RDD\n",
    "\n",
    "    Args:\n",
    "        line(string): string from the logline\n",
    "\n",
    "    Returns:\n",
    "        retval(LogLine): fills in the first two portions of the LogLine\n",
    "                         namedtuple\n",
    "    '''\n",
    "\n",
    "    # depends on tbird log structure\n",
    "    l = line.strip().rstrip().split(' ', 3)\n",
    "    return LogLine(float(l[2]), l[3], None, None, None)\n",
    "\n",
    "\n",
    "def lineRegexReplacement(line, logTrans):\n",
    "    '''\n",
    "    apply a list of regex replacements to a line, make note of\n",
    "    all the remplacements peformed in a dictionary(list)\n",
    "\n",
    "    Args:\n",
    "        line(LogLine): logline to work on\n",
    "\n",
    "    Globals:\n",
    "        transforms(RDD(TransformLine)): replacemnts to make with\n",
    "\n",
    "    Returns:\n",
    "        retval(LogLine): logline with the processed, and dictionary portions\n",
    "                         filled in\n",
    "    '''\n",
    "\n",
    "    text = line.msg.strip()\n",
    "    replaceDict = dict()\n",
    "\n",
    "    for t in logTrans.value:\n",
    "        if t.type == 'REPLACE':\n",
    "            replaceList = t.compiled.findall(text)\n",
    "            if replaceList:\n",
    "                replaceDict[t.NAME] = replaceList\n",
    "            text = t.compiled.sub(t.NAME, text, 0)\n",
    "\n",
    "        if t.type == 'REPLACELIST':\n",
    "            print 'REPLACELIST not implemented yet'\n",
    "\n",
    "    processed = ' '.join(text.split())\n",
    "    retVal = LogLine(line.ts, line.msg.lstrip().rstrip(),\n",
    "                     processed.lstrip().rstrip(), replaceDict, None)\n",
    "\n",
    "    return retVal\n",
    "\n",
    "\n",
    "def readTransforms(sc, transFile):\n",
    "    '''\n",
    "    returns a list of transforms for replacement processing\n",
    "\n",
    "    Args:\n",
    "        sc(sparkContext): spark context\n",
    "        transFile(string): uri to the transform file in HDFS\n",
    "\n",
    "    Returns:\n",
    "        retval(list(TransformLine))\n",
    "    '''\n",
    "\n",
    "    # map the transFile\n",
    "    simpleTransformations = sc.textFile(transFile)\n",
    "\n",
    "    # parse loglines\n",
    "    logTransforms = simpleTransformations.map(rdd_TransformLine).cache()\n",
    "\n",
    "    trans = logTransforms.collect()\n",
    "\n",
    "    lTrans = list()\n",
    "\n",
    "    for t in trans:\n",
    "        if t.id != 'COMMENT':\n",
    "            lTrans.append(t)\n",
    "\n",
    "    return lTrans\n",
    "\n",
    "\n",
    "def logPreProcess(sc, logTrans, rrdLogLine):\n",
    "    '''\n",
    "        take a series of loglines and pre-process the lines\n",
    "        replace ipaddresses, directories, urls, etc with constants\n",
    "        keep a dictionary of the replacements done to the line\n",
    "\n",
    "        Args:\n",
    "            sc(sparkContext): spark context\n",
    "            logTrans(string): location fo the transFile in HDFS\n",
    "            logFile(string): location of the log data in HDFS\n",
    "\n",
    "        Returns:\n",
    "            retval(RDD(LogLines)): preprocessed log lines ready for next\n",
    "                                   stage of processing\n",
    "   '''\n",
    "    \n",
    "    # following done to make sure that the broadcast gets to the function\n",
    "    return rrdLogLine.map(lambda line: lineRegexReplacement(line, logTrans))\n",
    "\n",
    "\n",
    "def rdd_preProcess(sc, logTrans, rrdLogLine):\n",
    "    '''\n",
    "    make a rdd of preprocessed loglines\n",
    "\n",
    "     Args:\n",
    "            sc(sparkContext): sparkContext\n",
    "            logTrans(string): location fo the transFile in HDFS\n",
    "            logFile(string): location of the log data in HDFS\n",
    "\n",
    "    Returns:\n",
    "            retval(RDD(LogLines)): preprocessed log lines ready for next\n",
    "                                   stage of processing\n",
    "    '''\n",
    "\n",
    "    lTrans = readTransforms(sc, logTrans)\n",
    "    logTrans = sc.broadcast(lTrans)\n",
    "    return logPreProcess(sc, logTrans, rrdLogLine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def procLogLine(line,logFile):\n",
    "    '''\n",
    "    handles the logfile specific parsing input lines into 2 parts\n",
    "    ts: timestamp float\n",
    "    msg: the rest of the message\n",
    "    \n",
    "    Args:\n",
    "        line(string): text to process\n",
    "        logFile(string): hint of URI used for input\n",
    "                         should use for switching parsing\n",
    "                         based off different directories\n",
    "    \n",
    "    Returns:\n",
    "        retval(list[string,string]): [ts, msg]\n",
    "    '''\n",
    "    return line.strip().rstrip().split(' ', 3)[2:]\n",
    "\n",
    "def rdd_LogLine(line,logFile):\n",
    "    '''\n",
    "    process a log line into a RDD\n",
    "\n",
    "    Args:\n",
    "        line(string): string from the logline\n",
    "        logFile(string): what URI the log lines came from,\n",
    "                         eventually want to do different parsing\n",
    "                         based on the base of the URI\n",
    "\n",
    "    Returns:\n",
    "        retval(LogLine): fills in the first two portions of the LogLine\n",
    "                         namedtuple\n",
    "    '''\n",
    "    l = procLogLine(line,logFile)\n",
    "    return LogLine(float(l[0]), l[1], None, None, None)\n",
    "\n",
    "def rdd_ReadLog(sc, logFile):\n",
    "    '''\n",
    "    read a log/directory into LogLine RDD format\n",
    "    NOTE: only ts, and msg are populated\n",
    "    Args:\n",
    "        sc(sparkContext)\n",
    "        logFile(string): URI to file toprocess\n",
    "\n",
    "    Returns:\n",
    "        retval(RDD(LogLines): RDD of logs read from the LogFile URI  \n",
    "    '''\n",
    "    sparkLogFile = sc.textFile(logFile)\n",
    "    \n",
    "    return sparkLogFile.map(   lambda line: rdd_LogLine(line, logFile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs = 'hdfs://namenode/magichour/tbird2.log'\n",
    "#logs = 'hdfs://namenode/user/dgrossman/tbird.log.10000.gz'\n",
    "trans = 'hdfs://namenode/magichour/simpleTrans'\n",
    "outDir = 'hdfs://namenode/magichour/2FebTry2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rddLogs = rdd_ReadLog(sc,logs)\n",
    "outData = rdd_preProcess(sc,trans,rddLogs)\n",
    "outData.saveAsTextFile(outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
