{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataFile = '/Users/dgrossman/data/spmf_fpgrowth_output.txt'\n",
    "dataFile = '/Users/dgrossman/work/netStorage/davec/tbird.TFIDF.60s.FPGrowth.minsup002'\n",
    "\n",
    "dataFile = '/Users/dgrossman/Downloads/PARIS_Results_500k.py'\n",
    "\n",
    "#dataFile = '/Users/dgrossman/work/netStorage/davec/8Jan2016/tbird.log.preProc.200.supports.30sec.Transactions.FPGrowth.3minsup'\n",
    "#dataFile = '/Users/dgrossman/work/netStorage/davec/8Jan2016/tbird.log.preProc.200.supports.20sec.Transactions.FPGrowth.02minsup'\n",
    "\n",
    "dataClusters = '/Users/dgrossman/data/tbird.log.preProc.200.supports.clusters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "edgeSet = set()\n",
    "edgeDict = defaultdict(int)\n",
    "procLine = list()\n",
    "clusterDict = dict()\n",
    "\n",
    "nodeFile = open(dataFile,'r')\n",
    "clusterFile = open(dataClusters,'r')\n",
    "\n",
    "#preproc for some later viz\n",
    "for line in clusterFile:\n",
    "    cluster,text = line.strip().split(',',1)\n",
    "    text = re.sub(r'\\s',' ',text)\n",
    "    text = re.sub(r'\\\\','',text)\n",
    "    text = re.sub(r'\\(:\\? ',' (:?',text)\n",
    "    text = re.sub(r'\\$','',text)\n",
    "    text = re.sub(r'([\\[\\]\\{\\}\\(\\):]) ',r'\\1',text)\n",
    "    text = re.sub(r' ([\\[\\]\\{\\}\\(\\):])',r'\\1',text)\n",
    "    \n",
    "    #kill the commas since they will break the CSV read used by the vis\n",
    "    text = re.sub(r',','',text)\n",
    "    clusterDict[cluster] = \" \".join(text.split())\n",
    "    \n",
    "#make sure that the junkdrawer is initialized\n",
    "clusterDict['-1'] = 'JunkDrawer'\n",
    "\n",
    "#handle the 2 types of MBA output formats\n",
    "for line in nodeFile:\n",
    "    if re.search('#SUP',line):\n",
    "        procLine.append(line.strip().split('#',1)[0].strip())\n",
    "    else:\n",
    "        procLine.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# quick check that things look ok\n",
    "#print procLine[:5]\n",
    "#print clusterDict['1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currenlty the market basket analysis we are performing is only looking within a time slice to determin if thigs are occuring at the same time, not if they can be used to predict what is in the next timeslice.\n",
    "\n",
    "for within the same basket \n",
    "nodes a,b,c,d listed as frequest should generate undirected edges\n",
    "(a,b) (a,c) (a,d) (b,c) (b,d) (c,d)\n",
    "\n",
    "for across baskets edges would generate directed edges\n",
    "(a,b) (b,c) (c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "for p in procLine:\n",
    "    l = p.split(' ')\n",
    "    if len(l) > 1:\n",
    "        comb = itertools.combinations(l, 2)\n",
    "        for start,finish in comb:\n",
    "            val = (start,finish)\n",
    "            edgeDict[val] += 1\n",
    "            edgeSet.add(val)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the output for the D3 force graph\n",
    "start edge, end edge, weight, start edge words, end edge words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "G=nx.Graph()\n",
    "G.add_edges_from(edgeDict.iterkeys())\n",
    "components = list(nx.connected_components(G))\n",
    "nodeweight = defaultdict(int)\n",
    "\n",
    "# make some relative size based on frequency\n",
    "for k,v in edgeDict.iteritems():\n",
    "    nodeweight[k[0]] += v\n",
    "    nodeweight[k[1]] += v\n",
    "\n",
    "#make the canvas the correct size for the number of\n",
    "#images to be generated\n",
    "numFigs = math.ceil(math.sqrt(len(components)))\n",
    "\n",
    "fig = plt.figure()\n",
    "edge2PicDict = dict()\n",
    "\n",
    "for e in edgeDict.iterkeys():\n",
    "    for index,c in enumerate(components):\n",
    "        if e[0] in c:\n",
    "            edge2PicDict[e]=index\n",
    "            \n",
    "temp = 1\n",
    "for c in components:\n",
    "    wordWeight = defaultdict(int)\n",
    "    wordList = list()\n",
    "    for cID in c:    \n",
    "        for word in clusterDict[cID].split():\n",
    "            #dont output punctuation\n",
    "            if word not in  [' ','{','}','[',']',':'] :\n",
    "                wordWeight[word] += nodeweight[cID]\n",
    "    for k,v in wordWeight.iteritems():\n",
    "        wordList.append((k,v))\n",
    "    \n",
    "    wordcloud = WordCloud(max_font_size=100,width=640,height=480, relative_scaling=.5).generate_from_frequencies(wordList)\n",
    "    ax= plt.subplot(numFigs,numFigs,temp)\n",
    "    plt.title('component:%i n:%i' % (temp-1,len(c)))\n",
    "    plt.imshow(wordcloud)\n",
    "    # puts the graphs into a file\n",
    "    wordcloud.to_file('wordCloud%i.png'%(temp-1))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    temp=temp+1\n",
    "    \n",
    "plt.show()\n",
    "fig.savefig('allWordCloud.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "dataOutFile = '/Users/dgrossman/work/magichour/d3/data3.csv'\n",
    "header = 'source,target,image,value,sTitle,tTitle\\n'\n",
    "outFile = open(dataOutFile,'w')\n",
    "outFile.write(header)\n",
    "for edge,count in edgeDict.iteritems():\n",
    "    o =  '%s,%s,%s,%f,%s %s,%s %s\\n' % (edge[0],edge[1],'wordCloud%i.png'%(edge2PicDict[edge]),\n",
    "                                        math.log(int(count))+1,\n",
    "                                        edge[0],clusterDict[edge[0]],\n",
    "                                        edge[1],clusterDict[edge[1]])\n",
    "    outFile.write(o)\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
