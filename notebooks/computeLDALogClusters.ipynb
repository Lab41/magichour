{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import math\n",
    "from collections import namedtuple\n",
    "from os import listdir\n",
    "import os\n",
    "%matplotlib\n",
    "Entry = namedtuple('Entry',['value','cluster'])\n",
    "TEntry = namedtuple('TEntry',['value','topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataDir = '/Users/dgrossman/data/'\n",
    "startsWith = 'tbirdBig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "files =  listdir(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filelist = list()\n",
    "for f in files:\n",
    "    if f.endswith('.out') and f.startswith(startsWith) and (os.path.getsize(dataDir+f) > 0):\n",
    "        filelist.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = dict()\n",
    "for f in filelist:\n",
    "    a = open('/Users/dgrossman/data/' + f,'r')\n",
    "    words = \"\"\n",
    "    for w in a.readlines():\n",
    "        words += w.lstrip().strip()\n",
    "        words += ' '\n",
    "    a.close()\n",
    "    documents[f] = words.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_set = list()\n",
    "for d in documents.itervalues():\n",
    "    doc_set.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for d in doc_set:\n",
    "    tokens = tokenizer.tokenize(d)\n",
    "    texts.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = 700\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=topics, id2word = dictionary, passes=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outData = list()\n",
    "for x in(ldamodel.print_topics(num_topics=topics, num_words=40)):\n",
    "    parts =  x[1].split('+')\n",
    "    sum = 0\n",
    "    lines = list()\n",
    "    empty = True\n",
    "    for p in parts:\n",
    "        val,cluster = p.lstrip().strip().split('*')\n",
    "       \n",
    "        if (sum + float(val) < .8) or empty:\n",
    "            sum += float(val)\n",
    "            \n",
    "            empty = False\n",
    "            lines.append(Entry(float(val),int(cluster)))\n",
    "            \n",
    "    outData.append((sum,lines))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "templateFile = '/Users/dgrossman/data/tbird.log.preProc.200.supports.clusters'\n",
    "tf = open(templateFile,'r').readlines()\n",
    "templateList = list()\n",
    "for t in tf:\n",
    "    # print t.strip()\n",
    "    unescaped= re.sub(r'[\\^]','',re.sub(r'[\\\\]', '', t)).strip()\n",
    "    templateList.append(unescaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for topic, X in enumerate(outData):\n",
    "    s = X[0]\n",
    "    ent = X[1]\n",
    "    print 'topic=%i|count=%i|energy=%f' % (topic, len(ent), s)\n",
    "    wordBag = set()\n",
    "    for e in ent:\n",
    "        cluster, string = templateList[e.cluster].split(',',1)\n",
    "        print '\\t%5i| %1.4f| %s' % (int(cluster),e.value,string)\n",
    "        for s in string.split():\n",
    "            wordBag.add(s)\n",
    "    print\n",
    "    print 'words used : %s' % ' '.join(sorted(wordBag))\n",
    "    print\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wc = list()\n",
    "\n",
    "for topic, X in enumerate(outData):\n",
    "    s = X[0]\n",
    "    ent = X[1]\n",
    "    print 'topic=%i|count=%i|energy=%f' % (topic, len(ent), s)\n",
    "    \n",
    "print \n",
    "for topic, X in enumerate(outData):\n",
    "    strength = X[0]\n",
    "    entries = X[1]\n",
    "    if strength > 0.4:\n",
    "        print 'topic=%i|count=%i|energy=%f' % (topic, len(entries), strength)\n",
    "        wordBag = set()\n",
    "        strongDict = dict()\n",
    "        strongList = list()\n",
    "        for e in entries:\n",
    "            cluster, string = templateList[e.cluster].split(',',1)\n",
    "            print '\\t%5i| %1.4f| %s' % (int(cluster),e.value,string)\n",
    "            \n",
    "            for value in string.split():\n",
    "                if value not in wordBag:\n",
    "                    wordBag.add(value)\n",
    "                    print 'adding',value,strength,e.value*100000\n",
    "                    strongDict[value] = e.value*100000  +1      \n",
    "                \n",
    "        print 'stuff',topic,strongDict\n",
    "        wc.append((topic,strongDict))\n",
    "        \n",
    "        print\n",
    "        print 'words used : %s' % ' '.join(sorted(wordBag))\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make wordcloud from high energy topics\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "items = len(wc)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "\n",
    "f =0\n",
    "for w in wc:\n",
    "    topic,wordFreqs = w\n",
    "    cloudWords = list()\n",
    "    for wordRel in wordFreqs.iteritems():\n",
    "        #print topic,wordRel\n",
    "        if not wordRel[0].isupper():\n",
    "            cloudWords.append(wordRel)\n",
    "    if len(cloudWords) > 0:\n",
    "        f += 1\n",
    "\n",
    "\n",
    "numFigs = math.ceil(math.sqrt(f))\n",
    "print numFigs,f\n",
    "\n",
    "temp =1\n",
    "for w in wc:\n",
    "   \n",
    "    topic,wordFreqs = w\n",
    "    cloudWords = list()\n",
    "    for wordRel in wordFreqs.iteritems():\n",
    "        #print topic,wordRel\n",
    "        if not wordRel[0].isupper():\n",
    "            cloudWords.append(wordRel)\n",
    "    if len(cloudWords) > 0:\n",
    "        wordcloud = WordCloud(max_font_size=40, relative_scaling=.5).generate_from_frequencies(cloudWords)\n",
    "        \n",
    "        plt.subplot(numFigs,numFigs,temp)\n",
    "        plt.title('topic %s' % topic)\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        temp = temp+1\n",
    "        \n",
    "plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outData2 = list()\n",
    "for x in(ldamodel.print_topics(num_topics=topics,num_words=40000)):\n",
    "    parts =  x[1].split('+')\n",
    "    sum = 0\n",
    "    lines = list()\n",
    "    for p in parts:\n",
    "        val,cluster = p.lstrip().strip().split('*')        \n",
    "        sum += float(val)\n",
    "        lines.append(Entry(float(val),int(cluster)))\n",
    "    outData2.append((sum,lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for topic, X in enumerate(outData2):\n",
    "    s = X[0]\n",
    "    ent = X[1]\n",
    "    print 'topic=%i|count=%i|energy=%f' % (topic, len(ent), s)\n",
    "    for e in ent:\n",
    "        if e.value > .01 :\n",
    "            print '\\t',topic,e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestCluster2Topic = dict()\n",
    "for topic, scoreList in enumerate(outData2):\n",
    "    score = scoreList[0]\n",
    "    ent = scoreList[1]\n",
    "    print topic\n",
    "    for cluster in ent:\n",
    "        if cluster.cluster in bestCluster2Topic:\n",
    "            current = bestCluster2Topic[cluster.cluster]\n",
    "            print current.value, cluster.value\n",
    "            if current.value < cluster.value:\n",
    "                bestCluster2Topic[cluster.cluster] = TEntry(cluster.value,topic)\n",
    "        else:\n",
    "            bestCluster2Topic[cluster.cluster] = TEntry(current.value,topic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic2Clust = dict()\n",
    "c2t = dict()\n",
    "for cluster,tval in bestCluster2Topic.iteritems():\n",
    "    c2t[cluster] = tval.topic\n",
    "\n",
    "for cluster,topic in c2t.iteritems():\n",
    "    if topic in topic2Clust:\n",
    "        c = topic2Clust[topic]\n",
    "        c.add(cluster)\n",
    "    else:\n",
    "        c = set()\n",
    "        c.add(cluster)\n",
    "        topic2Clust[topic]=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outMap = dict()\n",
    "for k,t in topic2Clust.iteritems():\n",
    "    for i in t:\n",
    "        outMap[i]=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print outMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
